{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v9 tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v9 r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from saphyra import crossval_table, get_color_fader\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-19 18:28:34,202 | Py.crossval_table                       INFO Reading file for v9 tag from /Volumes/castor/tuning_data/Zee/v9/*.v9_et*.r0/*/*.gz\n",
      "2020-12-19 18:28:34,202 | Py.crossval_table                       INFO There are 1250 files for this task...\n",
      "2020-12-19 18:28:34,202 | Py.crossval_table                       INFO Filling the table... \n",
      "2020-12-19 18:29:08,874 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v9/*.v9_et*.r0/*/*.gz', 'v9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_showers (InputLayer)      [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_rings_layer (Dense)       (None, 5)            505         Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_showers[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 10)           0           dense_rings_layer[0][0]          \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 5)            55          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            6           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings,data_shower], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "from saphyra.utils import correction_table\n",
    "ct  = correction_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1542.481434s.\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227619</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>23318</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>227583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977510</td>\n",
       "      <td>3073</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>227593</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977553</td>\n",
       "      <td>3004</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227780</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>24336</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>227740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978185</td>\n",
       "      <td>3138</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>227728</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978133</td>\n",
       "      <td>3044</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229996</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>31867</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987806</td>\n",
       "      <td>4272</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.022767</td>\n",
       "      <td>229975</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987785</td>\n",
       "      <td>4216</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.022469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230152</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>32748</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>230138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988485</td>\n",
       "      <td>4420</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>230171</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988626</td>\n",
       "      <td>4383</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.023359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137861</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>31938</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977567</td>\n",
       "      <td>3936</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.027399</td>\n",
       "      <td>137832</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977532</td>\n",
       "      <td>3873</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.026960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   227619   \n",
       "1  medium_cutbased       0        0                   227780   \n",
       "2   loose_cutbased       0        0                   229996   \n",
       "3  vloose_cutbased       0        0                   230152   \n",
       "4   tight_cutbased       0        1                   137861   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232819              0.977666                        23318   \n",
       "1                  232819              0.978360                        24336   \n",
       "2                  232819              0.987876                        31867   \n",
       "3                  232819              0.988548                        32748   \n",
       "4                  141000              0.977742                        31938   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      187639                  0.124271         227583  ...   \n",
       "1                      187639                  0.129701         227740  ...   \n",
       "2                      187639                  0.169837         229980  ...   \n",
       "3                      187639                  0.174527         230138  ...   \n",
       "4                      143657                  0.222321         137837  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977510               3073            187639        0.016377   \n",
       "1    0.978185               3138            187639        0.016724   \n",
       "2    0.987806               4272            187639        0.022767   \n",
       "3    0.988485               4420            187639        0.023556   \n",
       "4    0.977567               3936            143657        0.027399   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   227593                  232819              0.977553   \n",
       "1                   227728                  232819              0.978133   \n",
       "2                   229975                  232819              0.987785   \n",
       "3                   230171                  232819              0.988626   \n",
       "4                   137832                  141000              0.977532   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                         3004                      187639   \n",
       "1                         3044                      187639   \n",
       "2                         4216                      187639   \n",
       "3                         4383                      187639   \n",
       "4                         3873                      143657   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.016009  \n",
       "1                  0.016223  \n",
       "2                  0.022469  \n",
       "3                  0.023359  \n",
       "4                  0.026960  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "2020-12-19 18:55:34,233 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v9 tuning', \n",
    "                                              'correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf',\n",
    "                                              'correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta4.onnx\n",
      "2020-12-19 19:16:31,955 | Py.correction_table                     INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta4.onnx\n",
      "2020-12-19 19:17:41,451 | Py.correction_table                     INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta4.onnx\n",
      "2020-12-19 19:18:46,921 | Py.correction_table                     INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta4.onnx\n",
      "2020-12-19 19:19:54,458 | Py.correction_table                     INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-19 19:15:31.432443: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:31.445417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa91f2bc00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:31.445431: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:33.720723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:33.733528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f88ed795b00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:33.733546: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:36.046859: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:36.061649: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf30d65370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:36.061665: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:39.091145: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:39.108090: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9acb63240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:39.108106: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:41.701866: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:41.714608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee9e4a7fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:41.714622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:45.116596: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:45.135346: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f96ea414a20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:45.135372: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:47.545151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:47.557710: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa99fff6ca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:47.557725: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:50.345556: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:50.362507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f947ec3f390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:50.362533: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:53.696229: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:53.710520: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f817e52aaa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:53.710536: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:56.039108: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:56.052044: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcbdfd74f20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:56.052060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:15:58.303585: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:15:58.316077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8997dc6560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:15:58.316094: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:00.561361: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:00.574593: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc42d30570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:00.574608: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:02.880786: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:02.893940: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f800145ea80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:02.893956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:05.155272: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:05.168589: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe518750920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:05.168610: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:07.449065: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:07.461883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fceebbc3900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:07.461899: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:09.714010: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:09.726972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fabfc5b36a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:09.726987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:12.285820: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:12.301389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91c983db30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:12.301403: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:14.899186: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:14.911997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac608ce2e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:14.912012: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:17.398721: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:17.413792: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a25d319e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:17.413808: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:19.773402: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:19.786153: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba88c2a150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:19.786168: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:22.298742: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:22.312595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91058e3f90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:22.312611: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:24.613258: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:24.626859: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe8e145b4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:24.626873: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:26.950904: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:26.964091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feca5573110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:26.964106: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:29.289960: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:29.303254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fafbf31bfd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:29.303269: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:31.623721: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:31.639655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffbc47cb9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:31.639670: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:34.039811: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:34.053205: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff54432ff10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:34.053222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:36.470788: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:36.483736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8aa1c767e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:36.483751: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:38.944285: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:38.957108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f93a75390b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:38.957122: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:41.282058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:41.298461: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef5b457140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:41.298476: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:43.959523: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:43.972150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf1fde7e60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:43.972165: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:46.289523: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:46.302440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa3f53d6d70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:46.302456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:48.628594: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:48.641613: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc37ecbdf50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:48.641628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:50.910636: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:50.923594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f7ec1e670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:50.923609: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:53.212882: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:53.225756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdcd07ee8a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:53.225771: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:55.500642: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:55.513686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcdccd06ca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:55.513704: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:16:57.792185: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:16:57.805861: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faa3fc95230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:16:57.805876: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:00.131900: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:00.144949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2677b5f10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:00.144964: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:02.433815: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:02.446751: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc39ce05330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:02.446766: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:04.725386: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:04.737924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcab0396c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:04.737939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:07.045212: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:07.057846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f878e5e9fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:07.057861: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:10.105921: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:10.123703: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdae0c05290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:10.123730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:13.315371: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:13.332743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9ad475fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:13.332758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:16.839500: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:16.865901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb36d459d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:16.865930: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:20.083537: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:20.097307: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff59a49bef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:20.097321: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:23.339896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:23.353185: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f87b643e240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:23.353200: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:26.694955: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:26.718360: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcf05d135b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:26.718383: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:29.856716: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:29.875918: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc5b0b777d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:29.875942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:33.415643: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:33.455933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f96d1adb770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:33.455951: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:37.396561: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:37.413801: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa08db32b50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:37.413816: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:41.062973: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:41.078935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7bb2e4430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:41.078955: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:43.753449: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:43.769005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc423b86ad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:43.769040: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:46.616546: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:46.629817: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff972319a80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:46.629831: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:49.525949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:49.541659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2cafa7820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:49.541675: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:52.042608: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:52.055024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faafbd819b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:52.055039: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:54.431426: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:54.444721: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8f42f6f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:54.444736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:56.828677: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:56.841438: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2f555d5b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:56.841454: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:17:59.204183: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:17:59.216970: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fab7989e1c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:17:59.216985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:01.599429: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:01.612478: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf6bf7d880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:01.612494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:03.959805: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:03.973156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f89328dd060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:03.973170: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:06.324521: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:06.337847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc2a5ab5cd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:06.337861: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:08.793578: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:08.807099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92f0cb4f00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:08.807116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:11.154764: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:11.167917: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb78ed04c10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:11.167933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:13.528116: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:13.541151: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ebe5bb9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:13.541166: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:15.899297: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:15.912235: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb37afba8b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:15.912250: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:18.276949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:18.289634: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff852c76800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:18.289649: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:20.641645: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:20.654794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb3784b5eb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:20.654809: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:22.992072: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:23.004754: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcaa352fb30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:23.004769: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:25.338663: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:25.351341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9c44bef00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:25.351356: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:27.697288: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:27.710135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8cd0859080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:27.710151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:31.684568: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:31.700636: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f987aeec890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:31.700656: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:34.515252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:34.529404: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92354f1900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:34.529420: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:37.942027: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:37.961333: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faff9d8b6d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:37.961357: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:40.560710: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:40.573697: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcf5a31aac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:40.573711: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:43.582586: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:43.595536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8549a91270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:43.595551: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:46.557233: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:46.577814: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fded13d21c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:46.577836: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:49.452529: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:49.466496: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb96586be0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:49.466511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:51.893545: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:51.906955: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd1793949b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:51.906970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:54.272415: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:54.285797: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe389518860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:54.285822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:56.651679: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:56.665095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feffdf3dfb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:56.665111: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:18:59.028319: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:18:59.043883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9bc9c38470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:18:59.043920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:01.408194: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:01.421032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd38d41bb40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:01.421048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:03.754345: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:03.767688: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf95ab1640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:03.767705: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:06.094165: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:06.107839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba4c75ab60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:06.107854: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:08.377311: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:08.389764: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe615a4c10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:08.389788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:11.380403: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:11.395323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb1af8f6580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:11.395340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:14.446880: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:14.459551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9631c82da0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:14.459566: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:16.747147: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:16.759370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd8077bf10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:16.759387: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:19.020237: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:19.032391: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fed06c418f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:19.032405: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:22.034962: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:22.047657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda1ffe6270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:22.047671: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:24.727667: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:24.742280: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85c63ba090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:24.742295: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:28.002517: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:28.015756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feb6008b850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:28.015772: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:30.741731: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:30.761024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe88d39a4d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:30.761045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:34.094143: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:34.116594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb8ea8d2a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:34.116615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:36.820626: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:36.836282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb33d0bbe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:36.836303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:39.821080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:39.840332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f95f92c4790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:39.840363: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:43.088411: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:43.103110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f927250dd10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:43.103127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:45.750621: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:45.773330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9632b2b5a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:45.773352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:48.381484: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:48.395262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffbbf56a990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:48.395279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:51.020406: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:51.033637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc82d4c18c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:51.033654: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-19 19:19:53.990226: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-19 19:19:54.011194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec69aa9e20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-19 19:19:54.011223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
