{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v10 tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v10 r2 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 18:39:13,527 | Py.crossval_table                       INFO Reading file for v10 tag from /Volumes/castor/tuning_data/Zee/v10/*.v10_et*.r2/*/*.gz\n",
      "2020-12-27 18:39:13,527 | Py.crossval_table                       INFO There are 1250 files for this task...\n",
      "2020-12-27 18:39:13,527 | Py.crossval_table                       INFO Filling the table... \n",
      "2020-12-27 18:39:56,332 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v10/*.v10_et*.r2/*/*.gz', 'v10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "Reshape_layer (Reshape)      (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_layer_1 (Conv1D)      (None, 98, 4)             16        \n",
      "_________________________________________________________________\n",
      "conv1d_layer_2 (Conv1D)      (None, 96, 8)             104       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 16)                12304     \n",
      "_________________________________________________________________\n",
      "output_for_inference (Dense) (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 12,441\n",
      "Trainable params: 12,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1890.574528s.\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v10_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227619</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>23318</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>227578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977489</td>\n",
       "      <td>3507</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>227562</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977420</td>\n",
       "      <td>3375</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.017987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227780</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>24336</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>227751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978232</td>\n",
       "      <td>3582</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.019090</td>\n",
       "      <td>227728</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978133</td>\n",
       "      <td>3439</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229996</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>31867</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987759</td>\n",
       "      <td>4930</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.026274</td>\n",
       "      <td>229956</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987703</td>\n",
       "      <td>4750</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.025315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230152</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>32748</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>230129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988446</td>\n",
       "      <td>5071</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>230122</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988416</td>\n",
       "      <td>4910</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.026167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137861</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>31938</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977574</td>\n",
       "      <td>4814</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.033510</td>\n",
       "      <td>137825</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977482</td>\n",
       "      <td>4692</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.032661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   227619   \n",
       "1  medium_cutbased       0        0                   227780   \n",
       "2   loose_cutbased       0        0                   229996   \n",
       "3  vloose_cutbased       0        0                   230152   \n",
       "4   tight_cutbased       0        1                   137861   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232819              0.977666                        23318   \n",
       "1                  232819              0.978360                        24336   \n",
       "2                  232819              0.987876                        31867   \n",
       "3                  232819              0.988548                        32748   \n",
       "4                  141000              0.977742                        31938   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      187639                  0.124271         227578  ...   \n",
       "1                      187639                  0.129701         227751  ...   \n",
       "2                      187639                  0.169837         229969  ...   \n",
       "3                      187639                  0.174527         230129  ...   \n",
       "4                      143657                  0.222321         137838  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977489               3507            187639        0.018690   \n",
       "1    0.978232               3582            187639        0.019090   \n",
       "2    0.987759               4930            187639        0.026274   \n",
       "3    0.988446               5071            187639        0.027025   \n",
       "4    0.977574               4814            143657        0.033510   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   227562                  232819              0.977420   \n",
       "1                   227728                  232819              0.978133   \n",
       "2                   229956                  232819              0.987703   \n",
       "3                   230122                  232819              0.988416   \n",
       "4                   137825                  141000              0.977482   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                         3375                      187639   \n",
       "1                         3439                      187639   \n",
       "2                         4750                      187639   \n",
       "3                         4910                      187639   \n",
       "4                         4692                      143657   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.017987  \n",
       "1                  0.018328  \n",
       "2                  0.025315  \n",
       "3                  0.026167  \n",
       "4                  0.032661  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 19:11:54,224 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v10_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v10 tuning', \n",
    "                                              'correction_v10_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta4.onnx\n",
      "2020-12-27 19:13:10,655 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta4.onnx\n",
      "2020-12-27 19:14:08,882 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta4.onnx\n",
      "2020-12-27 19:15:07,636 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta4.onnx\n",
      "2020-12-27 19:16:05,844 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-27 19:12:13.766748: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:13.786096: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6b8d72f70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:13.786110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:16.122438: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:16.136525: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9bae5d77c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:16.136548: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:18.468547: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:18.481604: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff3cfe3bf90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:18.481634: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:20.828763: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:20.841966: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7ba4ce090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:20.841982: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:23.174964: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:23.189685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3cef1acb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:23.189702: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:25.569092: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:25.582429: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fddc9d5cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:25.582448: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:27.908506: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:27.921032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feaf758c140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:27.921047: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:30.247514: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:30.260358: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff782e0d520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:30.260372: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:32.664647: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:32.677602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7face0602b00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:32.677617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:35.031235: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:35.044777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe32cdb8710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:35.044793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:37.383634: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:37.398523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fafee6d6a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:37.398539: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:39.730208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:39.744548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f88e5585890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:39.744563: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:42.088210: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:42.101618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb470c3ea60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:42.101633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:44.460323: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:44.472688: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8154c2a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:44.472703: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:46.802305: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:46.814838: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec387d6010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:46.814853: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:49.138459: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:49.152146: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb89db79810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:49.152162: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:51.523313: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:51.537474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa8c6ad73e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:51.537497: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:53.871280: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:53.884510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbfb1df15a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:53.884524: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:56.223026: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:56.235785: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb33bd85d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:56.235800: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:12:58.548213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:12:58.560896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8924596a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:12:58.560910: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:00.882794: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:00.895593: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf524b8160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:00.895609: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:03.199801: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:03.212631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf4f48ea80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:03.212646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:05.560562: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:05.572873: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b0fdae170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:05.572888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:07.892030: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:07.904755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0af540c90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:07.904770: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:10.209053: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:10.221928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb315503450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:10.221942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:12.613309: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:12.626062: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8bafd161a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:12.626076: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:14.928210: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:14.940761: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe00ed61bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:14.940776: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:17.254699: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:17.267373: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd407fd59e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:17.267389: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:19.596105: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:19.608498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9afa08e040 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:19.608513: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:21.947255: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:21.959843: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdcba0bc0d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:21.959859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:24.267094: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:24.279731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa89a8eca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:24.279746: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:26.589742: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:26.602467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff5a6359af0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:26.602482: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:28.942458: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:28.955941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf044a4fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:28.955956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:31.269903: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:31.282121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3285d1300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:31.282136: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:33.576076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:33.588431: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9b0ed1fb90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:33.588449: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:35.890253: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:35.903079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faec6743160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:35.903094: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:38.218177: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:38.231003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa700c0b1d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:38.231018: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:40.566636: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:40.579410: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f955051f870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:40.579425: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:42.889878: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:42.902447: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb7705a560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:42.902462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:45.228386: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:45.240894: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd3c42cbd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:45.240908: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:47.540587: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:47.553138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff7c2c8fbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:47.553153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:49.857964: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:49.870523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc8fecb2800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:49.870538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:52.198226: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:52.210722: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcf55ce1f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:52.210736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:54.522039: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:54.534406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdc31ce5010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:54.534422: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:56.839834: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:56.852610: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c12bfa1d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:56.852625: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:13:59.165003: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:13:59.177647: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdc0ed03010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:13:59.177661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:01.508849: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:01.521485: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffd4ccf9f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:01.521500: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:03.854690: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:03.868104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc203da6140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:03.868120: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:06.178966: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:06.191625: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f93abd4d640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:06.191640: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:08.495628: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:08.507871: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe380558530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:08.507885: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:10.859544: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:10.871998: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe5092c7a80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:10.872013: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:13.243425: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:13.256240: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc5e35348f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:13.256255: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:15.623316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:15.636029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd5b1c86020 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:15.636044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:17.989856: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:18.002340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa57ad2b390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:18.002355: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:20.298340: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:20.310842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa214e2610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:20.310857: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:22.784699: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:22.798969: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff7220a5eb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:22.798985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:25.213492: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:25.226038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e72553680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:25.226053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:27.538288: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:27.550974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d0fdaae60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:27.550989: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:29.855952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:29.868474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdff964a510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:29.868489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:32.206457: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:32.219434: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f97b54f06b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:32.219449: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:34.553364: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:34.565933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc07e34ac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:34.565947: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:36.873507: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:36.885856: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f979abd95a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:36.885871: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:39.200416: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:39.212660: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e255640e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:39.212674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:41.645864: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:41.658282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc66e18140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:41.658296: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:43.972411: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:43.984944: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc8f6b82a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:43.984959: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:46.295653: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:46.308508: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc2ed756a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:46.308523: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:48.615111: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:48.627599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f95c94340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:48.627614: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:50.939878: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:50.952686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffbe2423df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:50.952703: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:53.270038: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:53.282265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe8c7d6d300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:53.282279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:55.588935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:55.601743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa264ca6bd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:55.601758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:14:57.912293: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:14:57.924978: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc0acaa920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:14:57.924994: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:00.245032: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:00.257603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc8d1d1aa40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:00.257621: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:02.599644: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:02.612437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82864cdfc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:02.612452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:04.924920: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:04.937490: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff825d7ff80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:04.937504: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:07.254278: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:07.267004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f823162cea0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:07.267019: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:09.622644: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:09.635814: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe9e2e108b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:09.635829: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:11.986789: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:11.999541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdabc539f20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:11.999557: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:14.297178: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:14.309933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fccb4cc8c90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:14.309948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:16.638015: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:16.650679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa866d44b90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:16.650694: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:18.960147: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:18.972749: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd0c97afe70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:18.972764: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:21.285222: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:21.301822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91c4f67cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:21.301843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:23.618199: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:23.630614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa8653fbef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:23.630628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:25.921787: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:25.934222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc8a512920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:25.934237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:28.238943: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:28.251548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3a85530d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:28.251562: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:30.560674: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:30.573136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b48c31080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:30.573150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:32.906027: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:32.919015: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdbd5e73450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:32.919030: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:35.237594: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:35.250195: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f992c6f6e60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:35.250209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:37.554317: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:37.566677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f994854a1a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:37.566692: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:39.877740: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:39.890394: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb61f04ff0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:39.890409: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:42.214880: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:42.227568: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe07afbc1e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:42.227583: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:44.542326: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:44.555182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff4ad6aba90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:44.555198: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:46.872434: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:46.884925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd0cb3762a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:46.884940: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:49.198989: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:49.211304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb286c9e340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:49.211319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:51.508967: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:51.527009: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f823bc57660 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:51.527024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:53.848499: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:53.861192: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fddfe50be80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:53.861208: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:56.155884: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:56.168384: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf11e415c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:56.168398: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:15:58.476726: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:15:58.489139: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcf6d4a03f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:15:58.489153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:16:00.809730: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:16:00.822155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba0fcb7be0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:16:00.822169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:16:03.140896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:16:03.153288: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc634bd6b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:16:03.153304: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 19:16:05.466204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 19:16:05.478905: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff0d1d365b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 19:16:05.478925: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
